def DOCKER_IMG = "registry.fedoraproject.org/fedora:28"
def DOCKER_ARGS = "--net=host -v /srv:/srv --privileged"

// this var conveniently refers to a location on the server as well as the local dir we sync to/from
def server_dir = "${env.ARTIFACT_SERVER_DIR}"
def output = "${server_dir}/images"
def repo = "${server_dir}/repo"

def ref = "openshift/3.10/x86_64/os";

node(env.NODE) {
    checkout scm

    stage("Provision") {
        sh """
           rpm -q imagefactory-plugins-TinMan \
                  libguestfs-tools-c \
                  rpm-ostree \
                  rsync || \
               dnf -y install ostree \
                              imagefactory-plugins-TinMan \
                              libguestfs-tools-c \
                              rpm-ostree \
                              rsync
           """
    }

    //stage("Sync In") {
    //    withCredentials([sshUserPrivateKey(credentialsId: env['ARTIFACT_SSH_CREDS_ID'],
    //                                       keyFileVariable: 'KEY_FILE')]) {
    //        sh """
    //            mkdir -p ${output}/cloud
    //            rsync -Hrlpt --stats \
    //                -e 'ssh -i ${env.KEY_FILE} \
    //                        -o UserKnownHostsFile=/dev/null \
    //                        -o StrictHostKeyChecking=no' \
    //                ${env.ARTIFACT_SERVER}:${server_dir}/{images,repo} ${server_dir}
    //        """
    //    }
    //}

    stage("Prepare Configs") {
        sh "sed -i 's,\\(<url>\\).*\\(<\\/url\\),\\1${env.INSTALLER_TREE_URL}\\2,' rhcos.tdl"
        sh "sed -i 's,@@OSTREE_INSTALL_URL@@,${env.OSTREE_INSTALL_URL},' cloud.ks"
        sh "sed -i 's,@@OSTREE_INSTALL_REF@@,${ref},' cloud.ks"
        sh "rm -rf /var/lib/imagefactory/storage/*"
    }

    stage("Running imagefactory") {
        sh """
            imagefactory --debug base_image \
                --file-parameter install_script cloud.ks \
                --parameter offline_icicle True \
                rhcos.tdl
        """
    }

    def commit, dirpath, qcow
    stage("Finalizing") {
        def image = sh(returnStdout: true, script: "ls /var/lib/imagefactory/storage/*.body").trim()
        // just introspect after the fact to avoid race conditions
        commit = sh(returnStdout: true,
                    script: """LIBGUESTFS_BACKEND=direct virt-cat -a ${image} -m /dev/coreos/root:/ \
                                    /ostree/repo/refs/remotes/rhcos/${ref}""").trim()
        currentBuild.description = 'commit ' + commit

        def dirname = (new Date()).format("YYYY-MM-dd-HH-mm-ss-") + commit
        dirpath = "${output}/cloud/${dirname}"
        qcow = "${dirpath}/rhcos.qcow2"
        vmdk = "${dirpath}/rhcos.vmdk"
        sh "mkdir -p ${dirpath}"

        sh "qemu-img convert -f raw -O qcow2 ${image} ${qcow}"
        sh "gzip ${qcow}"
        sh "qemu-img convert -f raw -O vmdk ${image} -o adapter_type=lsilogic,subformat=streamOptimized,compat6 ${vmdk}"

        sh "ln -sfn ${dirname} ${output}/cloud/latest"
        // just keep the last 2 (+ latest symlink)
        sh "cd ${output}/cloud && (ls | head -n -3 | xargs -r rm -rf)"
    }

    stage("Generate Metadata") {
        // XXX REMOVE THIS BEFORE SUBMITTING FOR PR
        sh "mkdir -p ${repo}"
        sh "ostree --repo=${repo} init --mode archive"
        sh "ostree --repo=${repo} remote add --if-not-exists --no-gpg-verify rhcos ${env.OSTREE_INSTALL_URL}"
        sh "ostree --repo=${repo} pull --depth=1 rhcos:${ref}"
        // XXX
        def prev_commit = sh(returnStdout: true,
                             script: "ostree --repo=${repo} rev-parse ${commit}^").trim()

        sh """
            rpm-ostree db list --repo=${repo} ${commit} > \
                /${dirpath}/${commit}.rpmlist
        """
        sh """
            rpm-ostree db diff --repo=${repo} \
                ${prev_commit} ${commit} > ${dirpath}/${commit}.pkgdiff
        """
        sh "sha256sum ${qcow}.gz | awk '{print \$1}' > ${qcow}.gz.sha256sum"
        sh "sha256sum ${vmdk} | awk '{print \$1}' > ${vmdk}.sha256sum"
    }

    //stage("Sync Out") {
    //    withCredentials([sshUserPrivateKey(credentialsId: env['ARTIFACT_SSH_CREDS_ID'],
    //                                       keyFileVariable: 'KEY_FILE')]) {
    //        sh """
    //            rsync -Hrlpt --stats --delete --delete-after \
    //                -e 'ssh -i ${env.KEY_FILE} \
    //                        -o UserKnownHostsFile=/dev/null \
    //                        -o StrictHostKeyChecking=no' \
    //                ${output}/ ${env.ARTIFACT_SERVER}:${output}
    //        """
    //    }
    //}

    //stage("Create AMI") {
    //    docker.image(DOCKER_IMG).inside(DOCKER_ARGS) {
    //        // not packaged yet, just build from src for now
    //        sh "dnf install -y git golang"
    //        sh "git clone https://github.com/coreos/mantle"
    //        sh "mantle/build ore"

    //        withCredentials([[$class: 'AmazonWebServicesCredentialsBinding',
    //                          credentialsId: env['AWS_CREDENTIALS']]]) {
    //            sh """
    //                # use a symlink so that our uploaded filename is unique
    //                ln -sf ${output}/cloud/latest/rhcos.vmdk rhcos-${commit}.vmdk
    //                mantle/bin/ore aws upload --region us-east-1 \
    //                    --ami-name 'rhcos_dev_${commit[0..6]}' \
    //                    --ami-description 'Red Hat CoreOS ${commit}' \
    //                    --bucket 's3://${env.S3_PRIVATE_BUCKET}/rhcos/cloud' \
    //                    --file rhcos-${commit}.vmdk \
    //                    --name "rhcos_dev_${commit[0..6]}" \
    //                    --delete-object # already default, just being explicit
    //            """
    //        }
    //    }
    //}
}
